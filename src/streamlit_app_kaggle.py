import streamlit as st
import os
import io
from PIL import Image
import requests
import torch
import google.generativeai as genai
import gc
import time
import sys
import psutil
import subprocess

# Configuration Kaggle
KAGGLE_USERNAME = st.secrets.get("kaggle_username", "")
KAGGLE_KEY = st.secrets.get("kaggle_key", "")

def setup_kaggle():
    """Configure l'acc√®s Kaggle"""
    try:
        # Cr√©er le dossier .kaggle s'il n'existe pas
        kaggle_dir = os.path.expanduser("~/.kaggle")
        os.makedirs(kaggle_dir, exist_ok=True)
        
        # Cr√©er le fichier kaggle.json
        kaggle_config = {
            "username": KAGGLE_USERNAME,
            "key": KAGGLE_KEY
        }
        
        import json
        with open(os.path.join(kaggle_dir, "kaggle.json"), "w") as f:
            json.dump(kaggle_config, f)
        
        # D√©finir les permissions (important sur Linux/Mac)
        os.chmod(os.path.join(kaggle_dir, "kaggle.json"), 0o600)
        
        st.success("‚úÖ Configuration Kaggle r√©ussie")
        return True
    except Exception as e:
        st.error(f"‚ùå Erreur configuration Kaggle: {e}")
        return False

def download_model_from_kaggle(dataset_name, local_path):
    """T√©l√©charge un mod√®le depuis Kaggle"""
    try:
        st.info(f"üì• T√©l√©chargement du mod√®le {dataset_name} depuis Kaggle...")
        
        # Installer kaggle si n√©cessaire
        try:
            import kaggle
        except ImportError:
            st.info("üì¶ Installation de l'API Kaggle...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "kaggle"])
            import kaggle
        
        # T√©l√©charger le dataset
        kaggle.api.dataset_download_files(dataset_name, path=local_path, unzip=True)
        st.success(f"‚úÖ Mod√®le t√©l√©charg√© avec succ√®s dans {local_path}")
        return True
    except Exception as e:
        st.error(f"‚ùå Erreur t√©l√©chargement Kaggle: {e}")
        return False

def load_model_with_kaggle_fallback():
    """Charge le mod√®le avec fallback vers Kaggle"""
    try:
        from transformers import AutoProcessor, Gemma3nForConditionalGeneration
        
        # Essayer d'abord Hugging Face
        st.info("üîÑ Tentative de chargement depuis Hugging Face...")
        
        model_id = "google/gemma-3n-E4B-it"
        
        try:
            # Charger le processeur depuis Hugging Face
            processor = AutoProcessor.from_pretrained(
                model_id,
                trust_remote_code=True,
                timeout=30  # Timeout de 30 secondes
            )
            
            # Charger le mod√®le
            model = Gemma3nForConditionalGeneration.from_pretrained(
                model_id,
                torch_dtype=torch.float32,
                trust_remote_code=True,
                low_cpu_mem_usage=True,
                timeout=60  # Timeout de 60 secondes
            )
            
            st.success("‚úÖ Mod√®le charg√© depuis Hugging Face")
            return model, processor
            
        except Exception as hf_error:
            st.warning(f"‚ö†Ô∏è √âchec Hugging Face: {hf_error}")
            
            # Essayer Kaggle comme fallback
            st.info("üîÑ Tentative de chargement depuis Kaggle...")
            
            if setup_kaggle():
                # T√©l√©charger le mod√®le depuis Kaggle
                kaggle_dataset = "google/gemma-3n-e4b-it"  # Exemple de dataset Kaggle
                local_path = "./models/kaggle_gemma"
                
                if download_model_from_kaggle(kaggle_dataset, local_path):
                    # Charger le mod√®le local t√©l√©charg√©
                    processor = AutoProcessor.from_pretrained(
                        local_path,
                        trust_remote_code=True
                    )
                    
                    model = Gemma3nForConditionalGeneration.from_pretrained(
                        local_path,
                        torch_dtype=torch.float32,
                        trust_remote_code=True,
                        low_cpu_mem_usage=True
                    )
                    
                    st.success("‚úÖ Mod√®le charg√© depuis Kaggle")
                    return model, processor
                else:
                    st.error("‚ùå √âchec du t√©l√©chargement depuis Kaggle")
            else:
                st.error("‚ùå Impossible de configurer Kaggle")
            
            # Fallback vers le mod√®le local existant
            st.info("üîÑ Tentative de chargement depuis le mod√®le local...")
            local_model_path = "D:/Dev/model_gemma"
            
            if os.path.exists(local_model_path):
                processor = AutoProcessor.from_pretrained(
                    local_model_path,
                    trust_remote_code=True
                )
                
                model = Gemma3nForConditionalGeneration.from_pretrained(
                    local_model_path,
                    torch_dtype=torch.float32,
                    trust_remote_code=True,
                    low_cpu_mem_usage=True
                )
                
                st.success("‚úÖ Mod√®le charg√© depuis le dossier local")
                return model, processor
            else:
                st.error("‚ùå Aucun mod√®le local trouv√©")
                return None, None
                
    except Exception as e:
        st.error(f"‚ùå Erreur g√©n√©rale de chargement: {e}")
        return None, None

# Interface utilisateur
st.set_page_config(
    page_title="AgriLens AI - Kaggle Integration",
    page_icon="üå±",
    layout="wide"
)

st.title("üå± AgriLens AI - Diagnostic des Maladies de Plantes")
st.markdown("### Version avec int√©gration Kaggle")

# Configuration Kaggle
with st.sidebar:
    st.header("üîß Configuration")
    
    # Champs pour les credentials Kaggle
    st.subheader("üìä Configuration Kaggle")
    kaggle_username = st.text_input("Nom d'utilisateur Kaggle", value=KAGGLE_USERNAME)
    kaggle_key = st.text_input("Cl√© API Kaggle", value=KAGGLE_KEY, type="password")
    
    if st.button("üîó Connecter Kaggle"):
        if kaggle_username and kaggle_key:
            # Mettre √† jour les secrets
            st.session_state.kaggle_username = kaggle_username
            st.session_state.kaggle_key = kaggle_key
            
            if setup_kaggle():
                st.success("‚úÖ Connexion Kaggle r√©ussie!")
        else:
            st.error("‚ùå Veuillez fournir les credentials Kaggle")

# Chargement du mod√®le
if 'model' not in st.session_state or st.session_state.model is None:
    st.info("üîÑ Chargement du mod√®le...")
    model, processor = load_model_with_kaggle_fallback()
    
    if model is not None and processor is not None:
        st.session_state.model = model
        st.session_state.processor = processor
        st.session_state.model_loaded = True
        st.success("‚úÖ Mod√®le charg√© avec succ√®s!")
    else:
        st.error("‚ùå Impossible de charger le mod√®le")
        st.stop()

# Interface principale
st.header("üì∏ Analyse d'Image")

uploaded_file = st.file_uploader(
    "Choisissez une image de plante √† analyser",
    type=['png', 'jpg', 'jpeg']
)

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Image t√©l√©charg√©e", use_column_width=True)
    
    if st.button("üîç Analyser l'image"):
        with st.spinner("Analyse en cours..."):
            # Analyse avec le mod√®le charg√©
            try:
                # Pr√©parer l'image
                inputs = st.session_state.processor(
                    image,
                    return_tensors="pt"
                )
                
                # G√©n√©rer la r√©ponse
                with torch.no_grad():
                    outputs = st.session_state.model.generate(
                        **inputs,
                        max_length=512,
                        num_return_sequences=1,
                        temperature=0.7
                    )
                
                # D√©coder la r√©ponse
                response = st.session_state.processor.decode(outputs[0], skip_special_tokens=True)
                
                st.success("‚úÖ Analyse termin√©e!")
                st.write("### üìã R√©sultats de l'analyse:")
                st.write(response)
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'analyse: {e}")

# Informations sur les sources de mod√®les
with st.expander("‚ÑπÔ∏è Sources de mod√®les disponibles"):
    st.markdown("""
    ### üìä Sources de mod√®les support√©es:
    
    1. **ü§ó Hugging Face** (par d√©faut)
       - Mod√®le: `google/gemma-3n-E4B-it`
       - Avantages: Rapide, toujours √† jour
       - Inconv√©nients: N√©cessite une connexion internet stable
    
    2. **üèÜ Kaggle** (fallback)
       - Mod√®le: Datasets Kaggle
       - Avantages: Alternative fiable, mod√®les optimis√©s
       - Inconv√©nients: N√©cessite un compte Kaggle
    
    3. **üíæ Mod√®le Local** (fallback)
       - Chemin: `D:/Dev/model_gemma`
       - Avantages: Fonctionne hors ligne
       - Inconv√©nients: N√©cessite un t√©l√©chargement pr√©alable
    
    ### üîß Configuration recommand√©e:
    - Cr√©ez un compte Kaggle gratuit
    - G√©n√©rez une cl√© API dans les param√®tres Kaggle
    - Configurez les credentials dans l'interface
    """)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    üå± AgriLens AI - Version avec int√©gration Kaggle<br>
    D√©velopp√© pour la comp√©tition Kaggle sur le diagnostic des maladies de plantes
</div>
""", unsafe_allow_html=True) 