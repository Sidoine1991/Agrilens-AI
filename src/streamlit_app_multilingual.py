import streamlit as st
import os
import io
from PIL import Image
import requests
import torch

# Configuration de la page
st.set_page_config(
    page_title="AgriLens AI - Plant Disease Diagnosis",
    page_icon="üå±",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# CSS pour mobile
st.markdown("""
<style>
@media (max-width: 600px) {
    .main {
        max-width: 100vw !important;
        padding: 0.5rem !important;
    }
    .stButton button, .stTextInput input, .stTextArea textarea {
        width: 100% !important;
        font-size: 1.1rem !important;
    }
    .stSidebar {
        width: 100vw !important;
        min-width: 100vw !important;
    }
    .result-box {
        font-size: 1.05rem !important;
    }
    .stMarkdown, .stHeader, .stSubheader {
        font-size: 1.1rem !important;
    }
    .stFileUploader, .stImage {
        width: 100% !important;
    }
}
</style>
""", unsafe_allow_html=True)

# Initialisation des variables de session
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'model_status' not in st.session_state:
    st.session_state.model_status = "Non charg√©"
if 'language' not in st.session_state:
    st.session_state.language = "fr"

# Dictionnaires de traductions
translations = {
    "fr": {
        "title": "üå± AgriLens AI - Diagnostic des Plantes",
        "subtitle": "**Application de diagnostic des maladies de plantes avec IA**",
        "config_title": "‚öôÔ∏è Configuration",
        "load_model": "Charger le mod√®le Gemma 2B",
        "model_status": "**Statut du mod√®le :**",
        "not_loaded": "Non charg√©",
        "loaded": "‚úÖ Charg√©",
        "error": "‚ùå Erreur",
        "tabs": ["üì∏ Analyse d'Image", "üí¨ Analyse de Texte", "üìñ Manuel", "‚ÑπÔ∏è √Ä propos"],
        "image_analysis_title": "üîç Diagnostic par Image",
        "image_analysis_desc": "T√©l√©chargez une photo de plante malade pour obtenir un diagnostic",
        "choose_image": "Choisissez une image...",
        "analyze_button": "üî¨ Analyser avec l'IA",
        "text_analysis_title": "üí¨ Diagnostic par Texte",
        "text_analysis_desc": "D√©crivez les sympt√¥mes de votre plante pour obtenir des conseils",
        "symptoms_desc": "Description des sympt√¥mes :",
        "analysis_results": "## üìä R√©sultats de l'Analyse",
        "manual_title": "üìñ Manuel Utilisateur",
        "about_title": "‚ÑπÔ∏è √Ä propos d'AgriLens AI",
        "creator_title": "üë®‚Äçüíª Cr√©ateur de l'Application",
        "creator_name": "**Sidoine Kolaol√© YEBADOKPO**",
        "creator_location": "Bohicon, R√©publique du B√©nin",
        "creator_phone": "+229 01 96 91 13 46",
        "creator_email": "syebadokpo@gmail.com",
        "creator_linkedin": "linkedin.com/in/sidoineko",
        "creator_portfolio": "Hugging Face Portfolio: Sidoineko/portfolio",
        "competition_title": "üèÜ Version Comp√©tition Kaggle",
        "competition_text": "Cette premi√®re version d'AgriLens AI a √©t√© d√©velopp√©e sp√©cifiquement pour participer √† la comp√©tition Kaggle. Elle repr√©sente notre premi√®re production publique et d√©montre notre expertise en IA appliqu√©e √† l'agriculture.",
        "footer": "*AgriLens AI - Diagnostic intelligent des plantes avec IA*"
    },
    "en": {
        "title": "üå± AgriLens AI - Plant Disease Diagnosis",
        "subtitle": "**AI-powered plant disease diagnosis application**",
        "config_title": "‚öôÔ∏è Configuration",
        "load_model": "Load Gemma 2B Model",
        "model_status": "**Model Status:**",
        "not_loaded": "Not loaded",
        "loaded": "‚úÖ Loaded",
        "error": "‚ùå Error",
        "tabs": ["üì∏ Image Analysis", "üí¨ Text Analysis", "üìñ Manual", "‚ÑπÔ∏è About"],
        "image_analysis_title": "üîç Image Diagnosis",
        "image_analysis_desc": "Upload a photo of a diseased plant to get a diagnosis",
        "choose_image": "Choose an image...",
        "analyze_button": "üî¨ Analyze with AI",
        "text_analysis_title": "üí¨ Text Diagnosis",
        "text_analysis_desc": "Describe your plant symptoms to get advice",
        "symptoms_desc": "Symptom description:",
        "analysis_results": "## üìä Analysis Results",
        "manual_title": "üìñ User Manual",
        "about_title": "‚ÑπÔ∏è About AgriLens AI",
        "creator_title": "üë®‚Äçüíª Application Creator",
        "creator_name": "**Sidoine Kolaol√© YEBADOKPO**",
        "creator_location": "Bohicon, Benin Republic",
        "creator_phone": "+229 01 96 91 13 46",
        "creator_email": "syebadokpo@gmail.com",
        "creator_linkedin": "linkedin.com/in/sidoineko",
        "creator_portfolio": "Hugging Face Portfolio: Sidoineko/portfolio",
        "competition_title": "üèÜ Kaggle Competition Version",
        "competition_text": "This first version of AgriLens AI was specifically developed to participate in the Kaggle competition. It represents our first public production and demonstrates our expertise in AI applied to agriculture.",
        "footer": "*AgriLens AI - Intelligent plant diagnosis with AI*"
    }
}

def t(key):
    return translations[st.session_state.language][key]

@st.cache_resource(show_spinner=False)
def load_model():
    """Charge un mod√®le plus l√©ger depuis Hugging Face"""
    try:
        st.info("Chargement du mod√®le Gemma 2B depuis Hugging Face...")
        
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        model_name = "google/gemma-2b-it"
        
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True
        )
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            device_map="auto",
            torch_dtype=torch.float32,
            trust_remote_code=True
        )
        
        st.success("Mod√®le Gemma 2B charg√© avec succ√®s !")
        return model, tokenizer
        
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None, None

def analyze_image_multilingual(image, prompt=""):
    """Analyse une image avec le mod√®le Gemma 2B"""
    if not st.session_state.model_loaded:
        return "‚ùå Mod√®le non charg√©. Veuillez le charger dans les r√©glages."
    
    try:
        model, tokenizer = st.session_state.model
        
        if st.session_state.language == "fr":
            if prompt:
                text_prompt = f"<start_of_turn>user\nAnalyse cette image de plante : {prompt}<end_of_turn>\n<start_of_turn>model\n"
            else:
                text_prompt = "<start_of_turn>user\nAnalyse cette image de plante et d√©cris les maladies pr√©sentes avec des recommandations pratiques.<end_of_turn>\n<start_of_turn>model\n"
        else:
            if prompt:
                text_prompt = f"<start_of_turn>user\nAnalyze this plant image: {prompt}<end_of_turn>\n<start_of_turn>model\n"
            else:
                text_prompt = "<start_of_turn>user\nAnalyze this plant image and describe the diseases present with practical recommendations.<end_of_turn>\n<start_of_turn>model\n"
        
        inputs = tokenizer(text_prompt, return_tensors="pt").to(model.device)
        
        with torch.inference_mode():
            generation = model.generate(
                **inputs,
                max_new_tokens=400,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
                pad_token_id=tokenizer.eos_token_id
            )
            generation = generation[0][inputs["input_ids"].shape[-1]:]
        
        response = tokenizer.decode(generation, skip_special_tokens=True)
        response = response.replace("<end_of_turn>", "").strip()
        
        if st.session_state.language == "fr":
            if "recommandation" not in response.lower() and "action" not in response.lower():
                response += "\n\n**Recommandations ou actions urgentes :**\n‚Ä¢ Isolez la plante malade si possible\n‚Ä¢ Appliquez un traitement adapt√©\n‚Ä¢ Surveillez les autres plantes\n‚Ä¢ Consultez un expert si n√©cessaire"
        else:
            if "recommendation" not in response.lower() and "action" not in response.lower():
                response += "\n\n**Recommendations or urgent actions:**\n‚Ä¢ Isolate the diseased plant if possible\n‚Ä¢ Apply appropriate treatment\n‚Ä¢ Monitor other plants\n‚Ä¢ Consult an expert if necessary"
        
        return response
        
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse d'image : {e}"

def analyze_text_multilingual(text):
    """Analyse un texte avec le mod√®le Gemma 2B"""
    if not st.session_state.model_loaded:
        return "‚ùå Mod√®le non charg√©. Veuillez le charger dans les r√©glages."
    
    try:
        model, tokenizer = st.session_state.model
        
        if st.session_state.language == "fr":
            prompt = f"<start_of_turn>user\nTu es un assistant agricole expert. Analyse ce probl√®me : {text}<end_of_turn>\n<start_of_turn>model\n"
        else:
            prompt = f"<start_of_turn>user\nYou are an expert agricultural assistant. Analyze this problem: {text}<end_of_turn>\n<start_of_turn>model\n"
        
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        
        with torch.inference_mode():
            generation = model.generate(
                **inputs,
                max_new_tokens=300,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                pad_token_id=tokenizer.eos_token_id
            )
            generation = generation[0][inputs["input_ids"].shape[-1]:]
        
        response = tokenizer.decode(generation, skip_special_tokens=True)
        response = response.replace("<end_of_turn>", "").strip()
        return response
        
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse de texte : {e}"

# Interface principale
st.title(t("title"))
st.markdown(t("subtitle"))

# Sidebar pour la configuration
with st.sidebar:
    st.header(t("config_title"))
    
    # S√©lecteur de langue
    st.subheader("üåê S√©lection de langue / Language Selection")
    language = st.selectbox(
        "Language / Langue",
        ["Fran√ßais", "English"],
        index=0 if st.session_state.language == "fr" else 1
    )
    
    if language == "Fran√ßais":
        st.session_state.language = "fr"
    else:
        st.session_state.language = "en"
    
    # Chargement du mod√®le
    if st.button(t("load_model"), type="primary"):
        with st.spinner("Chargement du mod√®le..." if st.session_state.language == "fr" else "Loading model..."):
            model, tokenizer = load_model()
            if model and tokenizer:
                st.session_state.model = (model, tokenizer)
                st.session_state.model_loaded = True
                st.session_state.model_status = t("loaded")
                st.success("Mod√®le charg√© avec succ√®s !" if st.session_state.language == "fr" else "Model loaded successfully!")
            else:
                st.session_state.model_loaded = False
                st.session_state.model_status = t("error")
                st.error("√âchec du chargement du mod√®le" if st.session_state.language == "fr" else "Model loading failed")
    
    st.info(f"{t('model_status')} {st.session_state.model_status}")

# Onglets principaux
tab1, tab2, tab3, tab4 = st.tabs(t("tabs"))

with tab1:
    st.header(t("image_analysis_title"))
    st.markdown(t("image_analysis_desc"))
    
    try:
        uploaded_file = st.file_uploader(
            t("choose_image"), 
            type=['png', 'jpg', 'jpeg'],
            help="Formats accept√©s : PNG, JPG, JPEG"
        )
        
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file)
                
                col1, col2 = st.columns([1, 1])
                with col1:
                    st.image(image, caption="Image upload√©e", use_container_width=True)
                
                with col2:
                    st.markdown("**Informations de l'image :**")
                    st.write(f"‚Ä¢ Format : {image.format}")
                    st.write(f"‚Ä¢ Taille : {image.size[0]}x{image.size[1]} pixels")
                    st.write(f"‚Ä¢ Mode : {image.mode}")
                
                question = st.text_area(
                    "Question sp√©cifique (optionnel) :",
                    placeholder="Ex: Quelle est cette maladie ? Que faire pour la traiter ?",
                    height=100
                )
                
                if st.button(t("analyze_button"), disabled=not st.session_state.model_loaded, type="primary"):
                    if not st.session_state.model_loaded:
                        st.error("‚ùå Veuillez d'abord charger le mod√®le dans les r√©glages")
                    else:
                        with st.spinner("üîç Analyse en cours..."):
                            result = analyze_image_multilingual(image, question)
                        
                        st.markdown(t("analysis_results"))
                        st.markdown("---")
                        st.markdown(result)
                        
            except Exception as e:
                st.error(f"‚ùå Erreur lors du traitement de l'image : {e}")
                st.info("üí° Essayez avec une image diff√©rente ou un format diff√©rent (PNG, JPG, JPEG)")
                
    except Exception as e:
        st.error(f"‚ùå Erreur lors de l'upload : {e}")
        st.info("üí° V√©rifiez que votre navigateur autorise les uploads de fichiers")

with tab2:
    st.header(t("text_analysis_title"))
    st.markdown(t("text_analysis_desc"))
    
    text_input = st.text_area(
        t("symptoms_desc"),
        placeholder="Ex: Mes tomates ont des taches brunes sur les feuilles et les fruits...",
        height=150
    )
    
    if st.button("üß† Analyser avec l'IA", disabled=not st.session_state.model_loaded, type="primary"):
        if not st.session_state.model_loaded:
            st.error("‚ùå Veuillez d'abord charger le mod√®le dans les r√©glages")
        elif not text_input.strip():
            st.error("‚ùå Veuillez saisir une description")
        else:
            with st.spinner("üîç Analyse en cours..."):
                result = analyze_text_multilingual(text_input)
            
            st.markdown(t("analysis_results"))
            st.markdown("---")
            st.markdown(result)

with tab3:
    st.header(t("manual_title"))
    
    if st.session_state.language == "fr":
        st.markdown("""
        ### üöÄ **D√©marrage Rapide**
        1. **Charger le mod√®le** : Cliquez sur 'Charger le mod√®le' dans les r√©glages
        2. **Choisir le mode** : Analyse d'image ou analyse de texte
        3. **Soumettre votre demande** : Upload d'image ou description
        4. **Obtenir le diagnostic** : R√©sultats avec recommandations
        
        ### üì∏ **Analyse d'Image**
        ‚Ä¢ **Formats accept√©s** : PNG, JPG, JPEG
        ‚Ä¢ **Taille recommand√©e** : 500x500 pixels minimum
        ‚Ä¢ **Qualit√©** : Image claire et bien √©clair√©e
        ‚Ä¢ **Focus** : Centrer sur la zone malade
        ‚Ä¢ **Question optionnelle** : Pr√©cisez votre pr√©occupation
        
        ### üí¨ **Analyse de Texte**
        ‚Ä¢ **Description d√©taill√©e** : Sympt√¥mes observ√©s
        ‚Ä¢ **Contexte** : Type de plante, conditions
        ‚Ä¢ **Historique** : √âvolution du probl√®me
        ‚Ä¢ **Actions d√©j√† tent√©es** : Traitements appliqu√©s
        
        ### üîç **Interpr√©tation des R√©sultats**
        ‚Ä¢ **Diagnostic** : Identification de la maladie
        ‚Ä¢ **Causes possibles** : Facteurs d√©clencheurs
        ‚Ä¢ **Recommandations** : Actions √† entreprendre
        ‚Ä¢ **Pr√©vention** : Mesures pr√©ventives
        
        ### üí° **Bonnes Pratiques**
        ‚Ä¢ **Images multiples** : Diff√©rents angles de la maladie
        ‚Ä¢ **√âclairage naturel** : √âviter les ombres
        ‚Ä¢ **Description pr√©cise** : D√©tails des sympt√¥mes
        ‚Ä¢ **Suivi r√©gulier** : Surveiller l'√©volution
        ‚Ä¢ **Consultation expert** : Pour cas complexes
        """)
    else:
        st.markdown("""
        ### üöÄ **Quick Start**
        1. **Load the model** : Click 'Load Model' in settings
        2. **Choose mode** : Image analysis or text analysis
        3. **Submit your request** : Upload image or description
        4. **Get diagnosis** : Results with recommendations
        
        ### üì∏ **Image Analysis**
        ‚Ä¢ **Accepted formats** : PNG, JPG, JPEG
        ‚Ä¢ **Recommended size** : 500x500 pixels minimum
        ‚Ä¢ **Quality** : Clear and well-lit image
        ‚Ä¢ **Focus** : Center on the diseased area
        ‚Ä¢ **Optional question** : Specify your concern
        
        ### üí¨ **Text Analysis**
        ‚Ä¢ **Detailed description** : Observed symptoms
        ‚Ä¢ **Context** : Plant type, conditions
        ‚Ä¢ **History** : Problem evolution
        ‚Ä¢ **Actions already tried** : Applied treatments
        
        ### üîç **Result Interpretation**
        ‚Ä¢ **Diagnosis** : Disease identification
        ‚Ä¢ **Possible causes** : Triggering factors
        ‚Ä¢ **Recommendations** : Actions to take
        ‚Ä¢ **Prevention** : Preventive measures
        
        ### üí° **Best Practices**
        ‚Ä¢ **Multiple images** : Different angles of the disease
        ‚Ä¢ **Natural lighting** : Avoid shadows
        ‚Ä¢ **Precise description** : Symptom details
        ‚Ä¢ **Regular monitoring** : Track evolution
        ‚Ä¢ **Expert consultation** : For complex cases
        """)

with tab4:
    st.header(t("about_title"))
    
    st.markdown("### üå± Notre Mission / Our Mission")
    st.markdown("AgriLens AI est une application de diagnostic des maladies de plantes utilisant l'intelligence artificielle pour aider les agriculteurs √† identifier et traiter les probl√®mes de leurs cultures.")
    
    st.markdown("### üöÄ Fonctionnalit√©s / Features")
    st.markdown("""
    ‚Ä¢ **Analyse d'images** : Diagnostic visuel des maladies
    ‚Ä¢ **Analyse de texte** : Conseils bas√©s sur les descriptions
    ‚Ä¢ **Recommandations pratiques** : Actions concr√®tes √† entreprendre
    ‚Ä¢ **Interface mobile** : Optimis√©e pour smartphones et tablettes
    ‚Ä¢ **Support multilingue** : Fran√ßais et Anglais
    """)
    
    st.markdown("### üîß Technologie / Technology")
    st.markdown("""
    ‚Ä¢ **Mod√®le** : Gemma 2B (version finale)
    ‚Ä¢ **Framework** : Streamlit
    ‚Ä¢ **D√©ploiement** : Hugging Face Spaces
    """)
    
    # Informations du cr√©ateur
    st.markdown(f"### {t('creator_title')}")
    st.markdown(f"{t('creator_name')}")
    st.markdown(f"üìç {t('creator_location')}")
    st.markdown(f"üìû {t('creator_phone')}")
    st.markdown(f"üìß {t('creator_email')}")
    st.markdown(f"üîó {t('creator_linkedin')}")
    st.markdown(f"üìÅ {t('creator_portfolio')}")
    
    # Informations de comp√©tition
    st.markdown(f"### {t('competition_title')}")
    st.markdown(t("competition_text"))
    
    st.markdown("### ‚ö†Ô∏è Avertissement / Warning")
    st.markdown("Les r√©sultats fournis sont √† titre indicatif uniquement. Pour un diagnostic professionnel, consultez un expert qualifi√©.")
    
    st.markdown("### üìû Support")
    st.markdown("Pour toute question ou probl√®me, consultez la documentation ou contactez l'√©quipe de d√©veloppement.")

# Footer
st.markdown("---")
st.markdown(t("footer")) 