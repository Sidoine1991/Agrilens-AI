import streamlit as st
import os
import io
from PIL import Image
import requests
import torch
import google.generativeai as genai

def resize_image_if_needed(image, max_size=(800, 800)):
    """
    Redimensionne l'image si elle d√©passe la taille maximale sp√©cifi√©e
    """
    width, height = image.size
    
    if width > max_size[0] or height > max_size[1]:
        # Calculer le ratio pour maintenir les proportions
        ratio = min(max_size[0] / width, max_size[1] / height)
        new_width = int(width * ratio)
        new_height = int(height * ratio)
        
        # Redimensionner l'image
        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        return resized_image, True  # True indique que l'image a √©t√© redimensionn√©e
    else:
        return image, False  # False indique que l'image n'a pas √©t√© redimensionn√©e

# Configuration de la page
st.set_page_config(
    page_title="AgriLens AI - Plant Disease Diagnosis",
    page_icon="üå±",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# Configuration pour √©viter les erreurs 403
st.markdown("""
<script>
// D√©sactiver les v√©rifications CORS pour les uploads
window.addEventListener('load', function() {
    if (typeof window.parent !== 'undefined' && window.parent !== window) {
        // Si l'app est dans un iframe (comme sur Hugging Face Spaces)
        console.log('Application d√©tect√©e dans un iframe - configuration sp√©ciale activ√©e');
    }
});
</script>
""", unsafe_allow_html=True)

# CSS pour mobile
st.markdown("""
<style>
@media (max-width: 600px) {
    .main {
        max-width: 100vw !important;
        padding: 0.5rem !important;
    }
    .stButton button, .stTextInput input, .stTextArea textarea {
        width: 100% !important;
        font-size: 1.1rem !important;
    }
    .stSidebar {
        width: 100vw !important;
        min-width: 100vw !important;
    }
    .result-box {
        font-size: 1.05rem !important;
    }
    .stMarkdown, .stHeader, .stSubheader {
        font-size: 1.1rem !important;
    }
    .stFileUploader, .stImage {
        width: 100% !important;
    }
}
</style>
""", unsafe_allow_html=True)

# Initialisation des variables de session
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'model_status' not in st.session_state:
    st.session_state.model_status = "Non charg√©"
if 'language' not in st.session_state:
    st.session_state.language = "fr"

# Configuration Gemini API
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-1.5-flash')
else:
    gemini_model = None

# Dictionnaires de traductions
translations = {
    "fr": {
        "title": "üå± AgriLens AI - Diagnostic des Plantes",
        "subtitle": "**Application de diagnostic des maladies de plantes avec IA**",
        "config_title": "‚öôÔ∏è Configuration",
        "load_model": "Charger le mod√®le Gemma 2B",
        "model_status": "**Statut du mod√®le :**",
        "not_loaded": "Non charg√©",
        "loaded": "‚úÖ Charg√©",
        "error": "‚ùå Erreur",
        "tabs": ["üì∏ Analyse d'Image", "üí¨ Analyse de Texte", "üìñ Manuel", "‚ÑπÔ∏è √Ä propos"],
        "image_analysis_title": "üîç Diagnostic par Image",
        "image_analysis_desc": "T√©l√©chargez une photo de plante malade pour obtenir un diagnostic",
        "choose_image": "Choisissez une image...",
        "analyze_button": "üî¨ Analyser avec l'IA",
        "text_analysis_title": "üí¨ Diagnostic par Texte",
        "text_analysis_desc": "D√©crivez les sympt√¥mes de votre plante pour obtenir des conseils",
        "symptoms_desc": "Description des sympt√¥mes :",
        "analysis_results": "## üìä R√©sultats de l'Analyse",
        "manual_title": "üìñ Manuel Utilisateur",
        "about_title": "‚ÑπÔ∏è √Ä propos d'AgriLens AI",
        "creator_title": "üë®‚Äçüíª Cr√©ateur de l'Application",
        "creator_name": "**Sidoine Kolaol√© YEBADOKPO**",
        "creator_location": "Bohicon, R√©publique du B√©nin",
        "creator_phone": "+229 01 96 91 13 46",
        "creator_email": "syebadokpo@gmail.com",
        "creator_linkedin": "linkedin.com/in/sidoineko",
        "creator_portfolio": "Hugging Face Portfolio: Sidoineko/portfolio",
        "competition_title": "üèÜ Version Comp√©tition Kaggle",
        "competition_text": "Cette premi√®re version d'AgriLens AI a √©t√© d√©velopp√©e sp√©cifiquement pour participer √† la comp√©tition Kaggle. Elle repr√©sente notre premi√®re production publique et d√©montre notre expertise en IA appliqu√©e √† l'agriculture.",
        "footer": "*AgriLens AI - Diagnostic intelligent des plantes avec IA*"
    },
    "en": {
        "title": "üå± AgriLens AI - Plant Disease Diagnosis",
        "subtitle": "**AI-powered plant disease diagnosis application**",
        "config_title": "‚öôÔ∏è Configuration",
        "load_model": "Load Gemma 2B Model",
        "model_status": "**Model Status:**",
        "not_loaded": "Not loaded",
        "loaded": "‚úÖ Loaded",
        "error": "‚ùå Error",
        "tabs": ["üì∏ Image Analysis", "üí¨ Text Analysis", "üìñ Manual", "‚ÑπÔ∏è About"],
        "image_analysis_title": "üîç Image Diagnosis",
        "image_analysis_desc": "Upload a photo of a diseased plant to get a diagnosis",
        "choose_image": "Choose an image...",
        "analyze_button": "üî¨ Analyze with AI",
        "text_analysis_title": "üí¨ Text Diagnosis",
        "text_analysis_desc": "Describe your plant symptoms to get advice",
        "symptoms_desc": "Symptom description:",
        "analysis_results": "## üìä Analysis Results",
        "manual_title": "üìñ User Manual",
        "about_title": "‚ÑπÔ∏è About AgriLens AI",
        "creator_title": "üë®‚Äçüíª Application Creator",
        "creator_name": "**Sidoine Kolaol√© YEBADOKPO**",
        "creator_location": "Bohicon, Benin Republic",
        "creator_phone": "+229 01 96 91 13 46",
        "creator_email": "syebadokpo@gmail.com",
        "creator_linkedin": "linkedin.com/in/sidoineko",
        "creator_portfolio": "Hugging Face Portfolio: Sidoineko/portfolio",
        "competition_title": "üèÜ Kaggle Competition Version",
        "competition_text": "This first version of AgriLens AI was specifically developed to participate in the Kaggle competition. It represents our first public production and demonstrates our expertise in AI applied to agriculture.",
        "footer": "*AgriLens AI - Intelligent plant diagnosis with AI*"
    }
}

def t(key):
    return translations[st.session_state.language][key]

@st.cache_resource(show_spinner=False)
def load_model():
    """Charge le mod√®le Gemma 3n E4B IT depuis Hugging Face"""
    try:
        st.info("Chargement du mod√®le Gemma 3n E4B IT depuis Hugging Face...")
        
        from transformers import AutoProcessor, Gemma3nForConditionalGeneration
        
        model_name = "google/gemma-3n-e4b-it"
        
        processor = AutoProcessor.from_pretrained(
            model_name,
            trust_remote_code=True
        )
        model = Gemma3nForConditionalGeneration.from_pretrained(
            model_name,
            device_map="auto",
            torch_dtype=torch.float32,
            trust_remote_code=True
        )
        
        st.success("Mod√®le Gemma 3n E4B IT charg√© avec succ√®s !")
        return model, processor
        
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {e}")
        return None, None

def analyze_image_multilingual(image, prompt=""):
    """Analyse une image avec Gemma 3n E4B IT pour diagnostic pr√©cis"""
    try:
        # V√©rifier si le mod√®le Gemma est charg√©
        if not st.session_state.model_loaded:
            return "‚ùå Mod√®le Gemma non charg√©. Veuillez d'abord charger le mod√®le dans les r√©glages."
        
        # R√©cup√©rer le mod√®le et le processeur
        model, processor = st.session_state.model, st.session_state.processor
        
        if not model or not processor:
            return "‚ùå Mod√®le Gemma non disponible. Veuillez recharger le mod√®le."
        
        # Pr√©parer le prompt pour Gemma 3n
        if st.session_state.language == "fr":
            if prompt:
                gemma_prompt = f"""
Tu es un expert en pathologie v√©g√©tale. Analyse cette image de plante et fournis un diagnostic pr√©cis.

**Question sp√©cifique :** {prompt}

**Instructions :**
1. **Diagnostic pr√©cis** : Identifie la maladie sp√©cifique avec son nom scientifique
2. **Causes** : Explique les causes probables (champignons, bact√©ries, virus, carences, etc.)
3. **Sympt√¥mes d√©taill√©s** : Liste tous les sympt√¥mes observables dans l'image
4. **Traitement sp√©cifique** : Donne des recommandations de traitement pr√©cises
5. **Actions pr√©ventives** : Conseils pour √©viter la propagation
6. **Urgence** : Indique si c'est urgent ou non

**Format de r√©ponse :**
## üîç **Diagnostic Pr√©cis**
[Nom de la maladie et causes]

## üìã **Sympt√¥mes D√©taill√©s**
[Liste des sympt√¥mes observ√©s]

## üíä **Traitement Recommand√©**
[Actions sp√©cifiques √† entreprendre]

## üõ°Ô∏è **Actions Pr√©ventives**
[Mesures pour √©viter la propagation]

## ‚ö†Ô∏è **Niveau d'Urgence**
[Urgent/Mod√©r√©/Faible]

R√©ponds de mani√®re structur√©e et pr√©cise.
"""
            else:
                gemma_prompt = """
Tu es un expert en pathologie v√©g√©tale. Analyse cette image de plante et fournis un diagnostic pr√©cis.

**Instructions :**
1. **Diagnostic pr√©cis** : Identifie la maladie sp√©cifique avec son nom scientifique
2. **Causes** : Explique les causes probables (champignons, bact√©ries, virus, carences, etc.)
3. **Sympt√¥mes d√©taill√©s** : Liste tous les sympt√¥mes observables dans l'image
4. **Traitement sp√©cifique** : Donne des recommandations de traitement pr√©cises
5. **Actions pr√©ventives** : Conseils pour √©viter la propagation
6. **Urgence** : Indique si c'est urgent ou non

**Format de r√©ponse :**
## üîç **Diagnostic Pr√©cis**
[Nom de la maladie et causes]

## üìã **Sympt√¥mes D√©taill√©s**
[Liste des sympt√¥mes observ√©s]

## üíä **Traitement Recommand√©**
[Actions sp√©cifiques √† entreprendre]

## üõ°Ô∏è **Actions Pr√©ventives**
[Mesures pour √©viter la propagation]

## ‚ö†Ô∏è **Niveau d'Urgence**
[Urgent/Mod√©r√©/Faible]

R√©ponds de mani√®re structur√©e et pr√©cise.
"""
        else:
            if prompt:
                gemma_prompt = f"""
You are an expert in plant pathology. Analyze this plant image and provide a precise diagnosis.

**Specific Question:** {prompt}

**Instructions:**
1. **Precise Diagnosis**: Identify the specific disease with its scientific name
2. **Causes**: Explain probable causes (fungi, bacteria, viruses, deficiencies, etc.)
3. **Detailed Symptoms**: List all observable symptoms in the image
4. **Specific Treatment**: Give precise treatment recommendations
5. **Preventive Actions**: Advice to prevent spread
6. **Urgency**: Indicate if urgent or not

**Response Format:**
## üîç **Precise Diagnosis**
[Disease name and causes]

## üìã **Detailed Symptoms**
[List of observed symptoms]

## üíä **Recommended Treatment**
[Specific actions to take]

## üõ°Ô∏è **Preventive Actions**
[Measures to prevent spread]

## ‚ö†Ô∏è **Urgency Level**
[Urgent/Moderate/Low]

Respond in a structured and precise manner.
"""
            else:
                gemma_prompt = """
You are an expert in plant pathology. Analyze this plant image and provide a precise diagnosis.

**Instructions:**
1. **Precise Diagnosis**: Identify the specific disease with its scientific name
2. **Causes**: Explain probable causes (fungi, bacteria, viruses, deficiencies, etc.)
3. **Detailed Symptoms**: List all observable symptoms in the image
4. **Specific Treatment**: Give precise treatment recommendations
5. **Preventive Actions**: Advice to prevent spread
6. **Urgency**: Indicate if urgent or not

**Response Format:**
## üîç **Precise Diagnosis**
[Disease name and causes]

## üìã **Detailed Symptoms**
[List of observed symptoms]

## üíä **Recommended Treatment**
[Specific actions to take]

## üõ°Ô∏è **Preventive Actions**
[Measures to prevent spread]

## ‚ö†Ô∏è **Urgency Level**
[Urgent/Moderate/Low]

Respond in a structured and precise manner.
"""
        
        # Pr√©parer les messages pour Gemma 3n
        messages = [
            {
                "role": "system",
                "content": [{"type": "text", "text": "You are an expert in plant pathology."}]
            },
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": gemma_prompt}
                ]
            }
        ]
        
        # Traiter les entr√©es avec le processeur
        inputs = processor.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        ).to(model.device)
        
        input_len = inputs["input_ids"].shape[-1]
        
        # G√©n√©rer la r√©ponse
        with torch.inference_mode():
            generation = model.generate(
                **inputs, 
                max_new_tokens=500, 
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1
            )
            generation = generation[0][input_len:]
        
        # D√©coder la r√©ponse
        response_text = processor.decode(generation, skip_special_tokens=True)
        
        if st.session_state.language == "fr":
            return f"""
## üß† **Analyse par Gemma 3n E4B IT**
{response_text}
"""
        else:
            return f"""
## üß† **Analysis by Gemma 3n E4B IT**
{response_text}
"""
        
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse d'image : {e}"

def analyze_text_multilingual(text):
    """Analyse un texte avec le mod√®le Gemma 2B"""
    if not st.session_state.model_loaded:
        return "‚ùå Mod√®le non charg√©. Veuillez le charger dans les r√©glages."
    
    try:
        model, tokenizer = st.session_state.model
        
        if st.session_state.language == "fr":
            prompt = f"<start_of_turn>user\nTu es un assistant agricole expert. Analyse ce probl√®me : {text}<end_of_turn>\n<start_of_turn>model\n"
        else:
            prompt = f"<start_of_turn>user\nYou are an expert agricultural assistant. Analyze this problem: {text}<end_of_turn>\n<start_of_turn>model\n"
        
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        
        with torch.inference_mode():
            generation = model.generate(
                **inputs,
                max_new_tokens=300,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                pad_token_id=tokenizer.eos_token_id
            )
            generation = generation[0][inputs["input_ids"].shape[-1]:]
        
        response = tokenizer.decode(generation, skip_special_tokens=True)
        response = response.replace("<end_of_turn>", "").strip()
        return response
        
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse de texte : {e}"

def analyze_with_gemini(gemma_description, image_info=""):
    """
    Analyse approfondie avec Gemini API pour diagnostic pr√©cis
    """
    if not gemini_model:
        return "‚ùå Gemini API non configur√©e. V√©rifiez votre cl√© API Google."
    
    try:
        if st.session_state.language == "fr":
            prompt = f"""
Tu es un expert en pathologie v√©g√©tale et en agriculture. Analyse cette description d'une plante malade et fournis un diagnostic pr√©cis.

**Description de Gemma :**
{gemma_description}

**Informations suppl√©mentaires :**
{image_info}

**Instructions :**
1. **Diagnostic pr√©cis** : Identifie la maladie sp√©cifique avec son nom scientifique
2. **Causes** : Explique les causes probables (champignons, bact√©ries, virus, carences, etc.)
3. **Sympt√¥mes d√©taill√©s** : Liste tous les sympt√¥mes observables
4. **Traitement sp√©cifique** : Donne des recommandations de traitement pr√©cises
5. **Actions pr√©ventives** : Conseils pour √©viter la propagation
6. **Urgence** : Indique si c'est urgent ou non

**Format de r√©ponse :**
## üîç **Diagnostic Pr√©cis**
[Nom de la maladie et causes]

## üìã **Sympt√¥mes D√©taill√©s**
[Liste des sympt√¥mes]

## üíä **Traitement Recommand√©**
[Actions sp√©cifiques √† entreprendre]

## üõ°Ô∏è **Actions Pr√©ventives**
[Mesures pour √©viter la propagation]

## ‚ö†Ô∏è **Niveau d'Urgence**
[Urgent/Mod√©r√©/Faible]

R√©ponds de mani√®re structur√©e et pr√©cise.
"""
        else:
            prompt = f"""
You are an expert in plant pathology and agriculture. Analyze this description of a diseased plant and provide a precise diagnosis.

**Gemma's Description:**
{gemma_description}

**Additional Information:**
{image_info}

**Instructions:**
1. **Precise Diagnosis**: Identify the specific disease with its scientific name
2. **Causes**: Explain probable causes (fungi, bacteria, viruses, deficiencies, etc.)
3. **Detailed Symptoms**: List all observable symptoms
4. **Specific Treatment**: Give precise treatment recommendations
5. **Preventive Actions**: Advice to prevent spread
6. **Urgency**: Indicate if urgent or not

**Response Format:**
## üîç **Precise Diagnosis**
[Disease name and causes]

## üìã **Detailed Symptoms**
[List of symptoms]

## üíä **Recommended Treatment**
[Specific actions to take]

## üõ°Ô∏è **Preventive Actions**
[Measures to prevent spread]

## ‚ö†Ô∏è **Urgency Level**
[Urgent/Moderate/Low]

Respond in a structured and precise manner.
"""
        
        response = gemini_model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        return f"‚ùå Erreur lors de l'analyse Gemini : {e}"

# Interface principale
st.title(t("title"))
st.markdown(t("subtitle"))

# Sidebar pour la configuration
with st.sidebar:
    st.header(t("config_title"))
    
    # S√©lecteur de langue
    st.subheader("üåê S√©lection de langue / Language Selection")
    language = st.selectbox(
        "Language / Langue",
        ["Fran√ßais", "English"],
        index=0 if st.session_state.language == "fr" else 1
    )
    
    if language == "Fran√ßais":
        st.session_state.language = "fr"
    else:
        st.session_state.language = "en"
    
    # Chargement du mod√®le
    if st.button(t("load_model"), type="primary"):
        with st.spinner("Chargement du mod√®le..." if st.session_state.language == "fr" else "Loading model..."):
            model, processor = load_model()
            if model and processor:
                st.session_state.model = model
                st.session_state.processor = processor
                st.session_state.model_loaded = True
                st.session_state.model_status = t("loaded")
                st.success("Mod√®le Gemma 3n E4B IT charg√© avec succ√®s !" if st.session_state.language == "fr" else "Gemma 3n E4B IT model loaded successfully!")
            else:
                st.session_state.model_loaded = False
                st.session_state.model_status = t("error")
                st.error("√âchec du chargement du mod√®le" if st.session_state.language == "fr" else "Model loading failed")
    
    st.info(f"{t('model_status')} {st.session_state.model_status}")
    
    # Statut du mod√®le Gemma 3n E4B IT
    if st.session_state.model_loaded:
        st.success("‚úÖ Mod√®le Gemma 3n E4B IT charg√©")
        st.info("Le mod√®le est pr√™t pour l'analyse d'images et de texte")
    else:
        st.warning("‚ö†Ô∏è Mod√®le Gemma 3n E4B IT non charg√©")
        st.info("Cliquez sur 'Charger le mod√®le' pour activer l'analyse")

# Onglets principaux
tab1, tab2, tab3, tab4 = st.tabs(t("tabs"))

with tab1:
    st.header(t("image_analysis_title"))
    st.markdown(t("image_analysis_desc"))
    
    # Options de capture d'image
    capture_option = st.radio(
        "Choisissez votre m√©thode :" if st.session_state.language == "fr" else "Choose your method:",
        ["üìÅ Upload d'image" if st.session_state.language == "fr" else "üìÅ Upload Image", 
         "üì∑ Capture par webcam" if st.session_state.language == "fr" else "üì∑ Webcam Capture"],
        horizontal=True
    )
    
    uploaded_file = None
    captured_image = None
    
    if capture_option == "üìÅ Upload d'image" or capture_option == "üìÅ Upload Image":
        try:
            uploaded_file = st.file_uploader(
                t("choose_image"), 
                type=['png', 'jpg', 'jpeg'],
                help="Formats accept√©s : PNG, JPG, JPEG (max 200MB)" if st.session_state.language == "fr" else "Accepted formats: PNG, JPG, JPEG (max 200MB)",
                accept_multiple_files=False,
                key="image_uploader"
            )
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'upload : {e}")
    
    else:  # Webcam capture
        st.markdown("**üì∑ Capture d'image par webcam**" if st.session_state.language == "fr" else "**üì∑ Webcam Image Capture**")
        st.info("üí° Positionnez votre plante malade devant la webcam et cliquez sur 'Prendre une photo'" if st.session_state.language == "fr" else "üí° Position your diseased plant in front of the webcam and click 'Take Photo'")
        
        captured_image = st.camera_input(
            "Prendre une photo de la plante" if st.session_state.language == "fr" else "Take a photo of the plant",
            key="webcam_capture"
        )
        
        # Traitement de l'image (upload ou webcam)
        image = None
        image_source = None
        
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file)
                image_source = "upload"
            except Exception as e:
                st.error(f"‚ùå Erreur lors du traitement de l'image upload√©e : {e}")
                st.info("üí° Essayez avec une image diff√©rente ou un format diff√©rent (PNG, JPG, JPEG)")
        elif captured_image is not None:
            try:
                image = Image.open(captured_image)
                image_source = "webcam"
            except Exception as e:
                st.error(f"‚ùå Erreur lors du traitement de l'image captur√©e : {e}")
                st.info("üí° Essayez de reprendre la photo")
        
        if image is not None:
            try:
                # Redimensionner l'image si n√©cessaire
                original_size = image.size
                image, was_resized = resize_image_if_needed(image, max_size=(800, 800))
                
                col1, col2 = st.columns([1, 1])
                with col1:
                    if image_source == "upload":
                        st.image(image, caption="Image upload√©e" if st.session_state.language == "fr" else "Uploaded Image", use_container_width=True)
                    else:
                        st.image(image, caption="Image captur√©e par webcam" if st.session_state.language == "fr" else "Webcam Captured Image", use_container_width=True)
                
                with col2:
                    st.markdown("**Informations de l'image :**")
                    st.write(f"‚Ä¢ Format : {image.format}")
                    st.write(f"‚Ä¢ Taille originale : {original_size[0]}x{original_size[1]} pixels")
                    st.write(f"‚Ä¢ Taille actuelle : {image.size[0]}x{image.size[1]} pixels")
                    st.write(f"‚Ä¢ Mode : {image.mode}")
                    
                    if was_resized:
                        st.warning("‚ö†Ô∏è L'image a √©t√© automatiquement redimensionn√©e pour optimiser le traitement")
                
                question = st.text_area(
                    "Question sp√©cifique (optionnel) :",
                    placeholder="Ex: Quelle est cette maladie ? Que faire pour la traiter ?",
                    height=100
                )
                
                if st.button(t("analyze_button"), disabled=not st.session_state.model_loaded, type="primary"):
                    if not st.session_state.model_loaded:
                        st.error("‚ùå Mod√®le Gemma non charg√©. Veuillez d'abord charger le mod√®le dans les r√©glages.")
                        st.info("üí° L'analyse d'image n√©cessite le mod√®le Gemma 3n E4B IT. Chargez-le dans les r√©glages.")
                    else:
                        with st.spinner("üîç Analyse en cours..."):
                            result = analyze_image_multilingual(image, question)
                        
                        st.markdown(t("analysis_results"))
                        st.markdown("---")
                        st.markdown(result)
            except Exception as e:
                error_msg = str(e)
                if "403" in error_msg or "Forbidden" in error_msg:
                    st.error("‚ùå Erreur 403 - Acc√®s refus√© lors du traitement de l'image")
                    st.warning("üîí Cette erreur indique un probl√®me d'autorisation c√¥t√© serveur.")
                    st.info("üí° Solutions possibles :")
                    st.info("‚Ä¢ V√©rifiez les logs de votre espace Hugging Face")
                    st.info("‚Ä¢ Essayez avec une image plus petite (< 1MB)")
                    st.info("‚Ä¢ Rafra√Æchissez la page et r√©essayez")
                    st.info("‚Ä¢ Contactez le support Hugging Face si le probl√®me persiste")
                else:
                    st.error(f"‚ùå Erreur lors du traitement de l'image : {e}")
                    st.info("üí° Essayez avec une image diff√©rente ou un format diff√©rent (PNG, JPG, JPEG)")

with tab2:
    st.header(t("text_analysis_title"))
    st.markdown(t("text_analysis_desc"))
    
    text_input = st.text_area(
        t("symptoms_desc"),
        placeholder="Ex: Mes tomates ont des taches brunes sur les feuilles et les fruits...",
        height=150
    )
    
    if st.button("üß† Analyser avec l'IA", disabled=not st.session_state.model_loaded, type="primary"):
        if not st.session_state.model_loaded:
            st.error("‚ùå Veuillez d'abord charger le mod√®le dans les r√©glages")
        elif not text_input.strip():
            st.error("‚ùå Veuillez saisir une description")
        else:
            with st.spinner("üîç Analyse en cours..."):
                result = analyze_text_multilingual(text_input)
            
            st.markdown(t("analysis_results"))
            st.markdown("---")
            st.markdown(result)

with tab3:
    st.header(t("manual_title"))
    
    if st.session_state.language == "fr":
        st.markdown("""
        ### üöÄ **D√©marrage Rapide**
        1. **Charger le mod√®le** : Cliquez sur 'Charger le mod√®le' dans les r√©glages
        2. **Choisir le mode** : Analyse d'image ou analyse de texte
        3. **Soumettre votre demande** : Upload d'image ou description
        4. **Obtenir le diagnostic** : R√©sultats avec recommandations
        
        ### üì∏ **Analyse d'Image**
        ‚Ä¢ **Formats accept√©s** : PNG, JPG, JPEG
        ‚Ä¢ **Taille recommand√©e** : 500x500 pixels minimum
        ‚Ä¢ **Qualit√©** : Image claire et bien √©clair√©e
        ‚Ä¢ **Focus** : Centrer sur la zone malade
        ‚Ä¢ **Question optionnelle** : Pr√©cisez votre pr√©occupation
        
        ### üí¨ **Analyse de Texte**
        ‚Ä¢ **Description d√©taill√©e** : Sympt√¥mes observ√©s
        ‚Ä¢ **Contexte** : Type de plante, conditions
        ‚Ä¢ **Historique** : √âvolution du probl√®me
        ‚Ä¢ **Actions d√©j√† tent√©es** : Traitements appliqu√©s
        
        ### üîç **Interpr√©tation des R√©sultats**
        ‚Ä¢ **Diagnostic** : Identification de la maladie
        ‚Ä¢ **Causes possibles** : Facteurs d√©clencheurs
        ‚Ä¢ **Recommandations** : Actions √† entreprendre
        ‚Ä¢ **Pr√©vention** : Mesures pr√©ventives
        
        ### üí° **Bonnes Pratiques**
        ‚Ä¢ **Images multiples** : Diff√©rents angles de la maladie
        ‚Ä¢ **√âclairage naturel** : √âviter les ombres
        ‚Ä¢ **Description pr√©cise** : D√©tails des sympt√¥mes
        ‚Ä¢ **Suivi r√©gulier** : Surveiller l'√©volution
        ‚Ä¢ **Consultation expert** : Pour cas complexes
        """)
    else:
        st.markdown("""
        ### üöÄ **Quick Start**
        1. **Load the model** : Click 'Load Model' in settings
        2. **Choose mode** : Image analysis or text analysis
        3. **Submit your request** : Upload image or description
        4. **Get diagnosis** : Results with recommendations
        
        ### üì∏ **Image Analysis**
        ‚Ä¢ **Accepted formats** : PNG, JPG, JPEG
        ‚Ä¢ **Recommended size** : 500x500 pixels minimum
        ‚Ä¢ **Quality** : Clear and well-lit image
        ‚Ä¢ **Focus** : Center on the diseased area
        ‚Ä¢ **Optional question** : Specify your concern
        
        ### üí¨ **Text Analysis**
        ‚Ä¢ **Detailed description** : Observed symptoms
        ‚Ä¢ **Context** : Plant type, conditions
        ‚Ä¢ **History** : Problem evolution
        ‚Ä¢ **Actions already tried** : Applied treatments
        
        ### üîç **Result Interpretation**
        ‚Ä¢ **Diagnosis** : Disease identification
        ‚Ä¢ **Possible causes** : Triggering factors
        ‚Ä¢ **Recommendations** : Actions to take
        ‚Ä¢ **Prevention** : Preventive measures
        
        ### üí° **Best Practices**
        ‚Ä¢ **Multiple images** : Different angles of the disease
        ‚Ä¢ **Natural lighting** : Avoid shadows
        ‚Ä¢ **Precise description** : Symptom details
        ‚Ä¢ **Regular monitoring** : Track evolution
        ‚Ä¢ **Expert consultation** : For complex cases
        """)

with tab4:
    st.header(t("about_title"))
    
    st.markdown("### üå± Notre Mission / Our Mission")
    st.markdown("AgriLens AI est une application de diagnostic des maladies de plantes utilisant l'intelligence artificielle pour aider les agriculteurs √† identifier et traiter les probl√®mes de leurs cultures.")
    
    st.markdown("### üöÄ Fonctionnalit√©s / Features")
    st.markdown("""
    ‚Ä¢ **Analyse d'images** : Diagnostic visuel des maladies
    ‚Ä¢ **Analyse de texte** : Conseils bas√©s sur les descriptions
    ‚Ä¢ **Recommandations pratiques** : Actions concr√®tes √† entreprendre
    ‚Ä¢ **Interface mobile** : Optimis√©e pour smartphones et tablettes
    ‚Ä¢ **Support multilingue** : Fran√ßais et Anglais
    """)
    
    st.markdown("### üîß Technologie / Technology")
    st.markdown("""
    ‚Ä¢ **Mod√®le** : Gemma 2B (version finale)
    ‚Ä¢ **Framework** : Streamlit
    ‚Ä¢ **D√©ploiement** : Hugging Face Spaces
    """)
    
    # Informations du cr√©ateur
    st.markdown(f"### {t('creator_title')}")
    st.markdown(f"{t('creator_name')}")
    st.markdown(f"üìç {t('creator_location')}")
    st.markdown(f"üìû {t('creator_phone')}")
    st.markdown(f"üìß {t('creator_email')}")
    st.markdown(f"üîó {t('creator_linkedin')}")
    st.markdown(f"üìÅ {t('creator_portfolio')}")
    
    # Informations de comp√©tition
    st.markdown(f"### {t('competition_title')}")
    st.markdown(t("competition_text"))
    
    st.markdown("### ‚ö†Ô∏è Avertissement / Warning")
    st.markdown("Les r√©sultats fournis sont √† titre indicatif uniquement. Pour un diagnostic professionnel, consultez un expert qualifi√©.")
    
    st.markdown("### üìû Support")
    st.markdown("Pour toute question ou probl√®me, consultez la documentation ou contactez l'√©quipe de d√©veloppement.")

# Footer
st.markdown("---")
st.markdown(t("footer")) 