import streamlit as st
from PIL import Image
from transformers import pipeline
import torch
import os

# Configuration de la page
st.set_page_config(
    page_title="AgriLens AI - Diagnostic des Plantes",
    page_icon="üå±",
    layout="wide"
)

@st.cache_resource
def load_model():
    """Charge le mod√®le Gemma 3n"""
    try:
        # V√©rification du token d'acc√®s
        if "HF_TOKEN" not in os.environ:
            st.error("Token d'acc√®s Hugging Face manquant. Veuillez configurer le token HF_TOKEN dans les param√®tres du Space.")
            return None
            
        pipe = pipeline(
            "image-text-to-text",
            model="google/gemma-3n-e4b-it",
            device_map="auto",
            torch_dtype=torch.bfloat16,
            model_kwargs={
                "trust_remote_code": True,
                "token": os.environ["HF_TOKEN"]
            }
        )
        return pipe
    except Exception as e:
        st.error(f"Erreur lors du chargement du mod√®le : {str(e)}")
        return None

def main():
    st.title("üå± AgriLens AI - Diagnostic des Plantes")
    st.markdown("### T√©l√©chargez une photo de plante pour analyse")

    # Chargement du mod√®le
    with st.spinner('Chargement du mod√®le Gemma 3n...'):
        model = load_model()
    
    if model is None:
        st.error("Impossible de charger le mod√®le. V√©rifiez les logs pour plus d'informations.")
        return

    # T√©l√©chargement de l'image
    uploaded_file = st.file_uploader(
        "Choisissez une image de plante...",
        type=["jpg", "jpeg", "png"]
    )

    if uploaded_file is not None:
        # Affichage de l'image
        image = Image.open(uploaded_file)
        st.image(image, caption='Image t√©l√©charg√©e', use_column_width=True)
        
        if st.button("Analyser l'image"):
            with st.spinner('Analyse en cours...'):
                try:
                    prompt = """Analyse cette image de plante et identifie les maladies potentielles.
                    Fournis une r√©ponse structur√©e avec :
                    1. Le nom de la plante (si identifiable)
                    2. Les maladies ou probl√®mes d√©tect√©s
                    3. Le niveau de confiance
                    4. Des recommandations de traitement
                    """
                    
                    # Appel au mod√®le
                    response = model(image, prompt=prompt, max_new_tokens=500)
                    
                    # Affichage des r√©sultats
                    st.markdown("### üîç R√©sultats de l'analyse")
                    st.markdown(response[0]['generated_text'])
                    
                except Exception as e:
                    st.error(f"Erreur lors de l'analyse : {str(e)}")

if __name__ == "__main__":
    main()