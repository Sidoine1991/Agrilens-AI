---
title: AgriLens AI
emoji: üå±
colorFrom: green
colorTo: yellow
sdk: docker
sdk_version: "1.0.0"
app_file: src/streamlit_app.py
pinned: false
---

# AgriLens AI üå±

Application de diagnostic des maladies des plantes utilisant le mod√®le Gemma 3n de Google.

## Fonctionnalit√©s
- Analyse d'images de plantes
- D√©tection des maladies
- Recommandations de traitement personnalis√©es

## Comment utiliser
1. T√©l√©chargez une photo d'une plante
2. Cliquez sur "Analyser l'image"
3. Consultez les r√©sultats d√©taill√©s

## Configuration requise
- Hardware: GPU recommand√©
- Espace disque: 20GB+ (pour le mod√®le Gemma 3n)

## Avertissement
Les r√©sultats fournis sont √† titre indicatif uniquement. Pour un diagnostic m√©dical ou agricole professionnel, veuillez consulter un expert qualifi√©.

## D√©veloppement
- Framework: Streamlit
- Mod√®le: google/gemma-3n-e4b-it
- Derni√®re mise √† jour: Juillet 2025

---

## üá´üá∑ Installation rapide
1. **T√©l√©chargez ou clonez ce d√©p√¥t**
2. **Placez le dossier du mod√®le Gemma 3n dans `models/`** (exemple : `models/gemma-3n-transformers-gemma-3n-e2b-it-v1`)
3. **Ouvrez un terminal dans le dossier du projet**
4. **Ex√©cutez le script d‚Äôinstallation automatique** :
   ```powershell
   python install_agrilens.py
   ```
5. **Lancez l‚Äôapplication** :
   ```powershell
   streamlit run src/streamlit_app.py
   ```

## üá¨üáß Quick install
1. **Download or clone this repo**
2. **Place the Gemma 3n model folder in `models/`** (e.g. `models/gemma-3n-transformers-gemma-3n-e2b-it-v1`)
3. **Open a terminal in the project folder**
4. **Run the auto-install script**:
   ```powershell
   python install_agrilens.py
   ```
5. **Launch the app**:
   ```powershell
   streamlit run src/streamlit_app.py
   ```

---

## üá´üá∑ Script d‚Äôinstallation automatique
Le script `install_agrilens.py` :
- Cr√©e l‚Äôenvironnement virtuel si besoin
- Installe toutes les d√©pendances (`requirements.txt`)
- V√©rifie la pr√©sence du mod√®le dans `models/`
- Affiche les instructions de lancement

## üá¨üáß Auto-install script
The `install_agrilens.py` script:
- Creates the virtual environment if needed
- Installs all dependencies (`requirements.txt`)
- Checks for the model in `models/`
- Shows launch instructions

---

## üá´üá∑ Modes de fonctionnement (local vs Hugging Face)

| Plateforme         | Mod√®le utilis√©                        | Inf√©rence r√©elle | D√©pendance Internet | Remarques |
|-------------------|---------------------------------------|------------------|---------------------|-----------|
| Local (offline)   | Mod√®le t√©l√©charg√© (dossier `models/`) | Oui              | Non                 | Rapide, 100% offline |
| Hugging Face (token HF) | google/gemma-3n-E2B-it (API HF)         | Oui              | Oui                 | Espace GPU recommand√©, token requis |
| Hugging Face (public)   | Aucun (mode d√©mo)                      | Non              | Oui                 | R√©ponse factice, test UI uniquement |

### Instructions
- **Local (offline)** :
  - Placez le mod√®le t√©l√©charg√© dans le dossier `models/`
  - Lancez l‚Äôapplication normalement (`streamlit run src/streamlit_app.py`)
  - Aucun acc√®s Internet requis
- **Hugging Face (inf√©rence r√©elle)** :
  - Ajoutez la variable d‚Äôenvironnement `HF_TOKEN` dans les settings du Space
  - Acceptez les conditions d‚Äôutilisation du mod√®le sur [la page du mod√®le](https://huggingface.co/google/gemma-3n-E2B-it)
  - Utilisez un Space GPU pour de meilleures performances
- **Hugging Face (mode d√©mo)** :
  - Si aucun token n‚Äôest pr√©sent, l‚Äôapplication reste en mode d√©mo (pas d‚Äôinf√©rence r√©elle, r√©ponse factice)

## üá¨üáß Modes of operation (local vs Hugging Face)

| Platform          | Model used                            | Real inference   | Internet required   | Notes     |
|-------------------|---------------------------------------|------------------|---------------------|-----------|
| Local (offline)   | Downloaded model (`models/` folder)   | Yes              | No                  | Fast, 100% offline |
| Hugging Face (HF token) | google/gemma-3n-E2B-it (HF API)           | Yes              | Yes                 | GPU Space recommended, token required |
| Hugging Face (public)   | None (demo mode)                         | No               | Yes                 | Fictive answer, UI test only |

### Instructions
- **Local (offline)** :
  - Put the downloaded model in the `models/` folder
  - Launch the app normally (`streamlit run src/streamlit_app.py`)
  - No Internet required
- **Hugging Face (real inference)** :
  - Add the `HF_TOKEN` environment variable in the Space settings
  - Accept the model terms on [the model page](https://huggingface.co/google/gemma-3n-E2B-it)
  - Use a GPU Space for best performance
- **Hugging Face (demo mode)** :
  - If no token is present, the app stays in demo mode (no real inference, fake answer)