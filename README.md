---
title: AgriLens AI
emoji: üå±
colorFrom: green
colorTo: yellow
sdk: docker
sdk_version: "1.0.0"
app_file: src/streamlit_app_local_models.py
pinned: false
---

# AgriLens AI üå±

Application de diagnostic des maladies des plantes utilisant le mod√®le Gemma 3n multimodal de Google en mode local.

## ‚ú® Fonctionnalit√©s principales
- **Analyse d'images de plantes** avec IA locale
- **Diagnostic automatique** des maladies et probl√®mes
- **Recommandations pratiques** avec section "Actions urgentes"
- **Interface mobile** optimis√©e pour les agriculteurs
- **Mod√®le multimodal** : analyse image + texte simultan√©ment
- **Mode 100% offline** - aucune connexion Internet requise

## üöÄ Comment utiliser
1. **Chargez le mod√®le** : Cliquez sur "Charger le mod√®le Gemma 3n multimodal" dans la sidebar
2. **T√©l√©chargez une photo** de plante malade
3. **Posez une question** sp√©cifique (optionnel)
4. **Cliquez sur "Analyser avec l'IA Locale"**
5. **Consultez le diagnostic** et les recommandations

## üíª Configuration requise
- **Hardware** : CPU (GPU optionnel)
- **Espace disque** : 20GB+ (pour le mod√®le Gemma 3n)
- **M√©moire RAM** : 8GB minimum recommand√©
- **Syst√®me** : Windows 10/11, Linux, macOS

## ‚ö†Ô∏è Avertissement
Les r√©sultats fournis sont √† titre indicatif uniquement. Pour un diagnostic m√©dical ou agricole professionnel, veuillez consulter un expert qualifi√©.

## üîß D√©veloppement
- **Framework** : Streamlit
- **Mod√®le** : Gemma 3n multimodal (local)
- **G√©n√©ration** : Param√®tres optimis√©s (temperature=0.7, top_p=0.9)
- **Interface** : Responsive design mobile-first
- **Derni√®re mise √† jour** : Juillet 2025

---

## üá´üá∑ Installation rapide
1. **T√©l√©chargez ou clonez ce d√©p√¥t**
2. **Placez le mod√®le Gemma 3n dans `D:/Dev/model_gemma`** (ou modifiez le chemin dans le code)
3. **Ouvrez un terminal dans le dossier du projet**
4. **Ex√©cutez le script d'installation automatique** :
   ```powershell
   python install_agrilens.py
   ```
5. **Lancez l'application** :
   ```powershell
   streamlit run src/streamlit_app_local_models.py
   ```

## üá¨üáß Quick install
1. **Download or clone this repo**
2. **Place the Gemma 3n model in `D:/Dev/model_gemma`** (or modify the path in the code)
3. **Open a terminal in the project folder**
4. **Run the auto-install script**:
   ```powershell
   python install_agrilens.py
   ```
5. **Launch the app**:
   ```powershell
   streamlit run src/streamlit_app_local_models.py
   ```

---

## üá´üá∑ Nouvelles fonctionnalit√©s (v2.0)

### üéØ Mod√®le multimodal local
- **Gemma 3n multimodal** : Analyse simultan√©e image + texte
- **Param√®tres optimis√©s** : G√©n√©ration fluide sans caract√®res isol√©s
- **400 tokens** : R√©ponses d√©taill√©es et compl√®tes

### üì± Interface mobile
- **Design responsive** : Optimis√© pour smartphones et tablettes
- **Sidebar collapsible** : Plus d'espace sur mobile
- **Boutons adapt√©s** : Taille et espacement optimis√©s
- **Feedback visuel** : Spinners et messages de statut

### üîç Diagnostic am√©lior√©
- **Section automatique** : "Recommandations ou actions urgentes"
- **Analyse contextuelle** : Prise en compte de la question utilisateur
- **Conseils pratiques** : Actions prioritaires pour l'agriculteur

### ‚ö° Performance
- **Chargement unique** : Mod√®le charg√© une seule fois avec cache
- **CPU optimis√©** : Fonctionne sans GPU
- **Feedback temps r√©el** : Indicateurs de progression

## üá¨üáß New features (v2.0)

### üéØ Local multimodal model
- **Gemma 3n multimodal** : Simultaneous image + text analysis
- **Optimized parameters** : Smooth generation without isolated characters
- **400 tokens** : Detailed and complete responses

### üì± Mobile interface
- **Responsive design** : Optimized for smartphones and tablets
- **Collapsible sidebar** : More space on mobile
- **Adapted buttons** : Optimized size and spacing
- **Visual feedback** : Spinners and status messages

### üîç Enhanced diagnosis
- **Automatic section** : "Recommendations or urgent actions"
- **Contextual analysis** : User question consideration
- **Practical advice** : Priority actions for farmers

### ‚ö° Performance
- **Single loading** : Model loaded once with cache
- **CPU optimized** : Works without GPU
- **Real-time feedback** : Progress indicators

---

## üá´üá∑ Script d'installation automatique
Le script `install_agrilens.py` :
- Cr√©e l'environnement virtuel si besoin
- Installe toutes les d√©pendances (`requirements.txt`)
- V√©rifie la pr√©sence du mod√®le
- Affiche les instructions de lancement

## üá¨üáß Auto-install script
The `install_agrilens.py` script:
- Creates the virtual environment if needed
- Installs all dependencies (`requirements.txt`)
- Checks for the model presence
- Shows launch instructions

---

## üá´üá∑ Modes de fonctionnement

| Mode               | Mod√®le utilis√©                        | Inf√©rence r√©elle | D√©pendance Internet | Remarques |
|-------------------|---------------------------------------|------------------|---------------------|-----------|
| **Local (offline)** | Gemma 3n multimodal (dossier local)   | ‚úÖ Oui           | ‚ùå Non              | Rapide, 100% offline, recommand√© |
| Hugging Face (token HF) | google/gemma-3n-E2B-it (API HF)         | ‚úÖ Oui           | ‚úÖ Oui              | Espace GPU recommand√©, token requis |
| Hugging Face (public)   | Aucun (mode d√©mo)                      | ‚ùå Non           | ‚úÖ Oui              | R√©ponse factice, test UI uniquement |

### Instructions
- **Local (offline)** - **RECOMMAND√â** :
  - Placez le mod√®le Gemma 3n dans `D:/Dev/model_gemma`
  - Lancez `streamlit run src/streamlit_app_local_models.py`
  - Aucun acc√®s Internet requis
  - Interface mobile optimis√©e
- **Hugging Face (inf√©rence r√©elle)** :
  - Ajoutez la variable d'environnement `HF_TOKEN`
  - Acceptez les conditions d'utilisation du mod√®le
  - Utilisez un Space GPU pour de meilleures performances
- **Hugging Face (mode d√©mo)** :
  - Si aucun token n'est pr√©sent, mode d√©mo uniquement

## üá¨üáß Operating modes

| Mode               | Model used                            | Real inference   | Internet required   | Notes     |
|-------------------|---------------------------------------|------------------|---------------------|-----------|
| **Local (offline)** | Gemma 3n multimodal (local folder)    | ‚úÖ Yes           | ‚ùå No               | Fast, 100% offline, recommended |
| Hugging Face (HF token) | google/gemma-3n-E2B-it (HF API)           | ‚úÖ Yes           | ‚úÖ Yes              | GPU Space recommended, token required |
| Hugging Face (public)   | None (demo mode)                         | ‚ùå No            | ‚úÖ Yes              | Fictive answer, UI test only |

### Instructions
- **Local (offline)** - **RECOMMENDED** :
  - Put the Gemma 3n model in `D:/Dev/model_gemma`
  - Launch `streamlit run src/streamlit_app_local_models.py`
  - No Internet required
  - Mobile-optimized interface
- **Hugging Face (real inference)** :
  - Add the `HF_TOKEN` environment variable
  - Accept the model terms of use
  - Use a GPU Space for best performance
- **Hugging Face (demo mode)** :
  - If no token is present, demo mode only