# =================================================================================
# ANALYSE D'IMAGE DE PLANTE MALADE AVEC GEMMA 3N
# Auteur : Sidoine Kolaol√© YEBADOKPO
# =================================================================================

import torch
import time
from PIL import Image
import os

def load_multimodal_model():
    """Charge le mod√®le multimodal pour l'analyse d'images"""
    try:
        print("üñºÔ∏è Chargement du mod√®le multimodal...")
        
        from transformers import AutoProcessor, AutoModelForImageTextToText
        
        # Chemin du mod√®le
        GEMMA_PATH = "/kaggle/input/gemma-3n/transformers/gemma-3n-e2b-it/1"
        
        # Chargement du processeur
        processor = AutoProcessor.from_pretrained(
            GEMMA_PATH,
            local_files_only=True,
            trust_remote_code=True
        )
        
        # Chargement du mod√®le multimodal (CPU pour √©conomiser la m√©moire)
        multimodal_model = AutoModelForImageTextToText.from_pretrained(
            GEMMA_PATH,
            local_files_only=True,
            trust_remote_code=True,
            device_map="cpu",
            torch_dtype=torch.float32
        )
        
        print("‚úÖ Mod√®le multimodal charg√© avec succ√®s")
        return processor, multimodal_model
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le multimodal: {e}")
        return None, None

def analyze_plant_image(image_path: str, processor, model, custom_prompt: str = None):
    """Analyse une image de plante malade"""
    
    try:
        print(f"\nüñºÔ∏è Analyse de l'image: {image_path}")
        
        # V√©rification de l'existence de l'image
        if not os.path.exists(image_path):
            print(f"‚ùå Image non trouv√©e: {image_path}")
            return None
        
        # Chargement et pr√©paration de l'image
        image = Image.open(image_path).convert("RGB")
        image = image.resize((224, 224))  # Redimensionnement pour √©conomiser la m√©moire
        
        print(f"‚úÖ Image charg√©e: {image.size}")
        
        # Affichage de l'image (optionnel)
        try:
            from IPython.display import display
            display(image)
        except:
            print("üì∏ Image pr√™te pour analyse")
        
        # Prompt par d√©faut pour le diagnostic agricole
        if custom_prompt is None:
            prompt = (
                "Analyse cette image de plante. D√©cris les sympt√¥mes visibles et "
                "fournis un diagnostic structur√© incluant:\n"
                "1. Nom de la maladie probable\n"
                "2. Sympt√¥mes observ√©s (couleur, forme, r√©partition)\n"
                "3. Causes possibles\n"
                "4. Traitements recommand√©s\n"
                "5. Mesures pr√©ventives pour l'avenir"
            )
        else:
            prompt = custom_prompt
        
        print(f"üìù Prompt d'analyse: {prompt[:100]}...")
        
        # Pr√©paration des inputs
        inputs = processor(
            text=prompt,
            images=image,
            return_tensors="pt"
        )
        
        # G√©n√©ration du diagnostic
        start_time = time.time()
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=400,  # Plus de tokens pour un diagnostic d√©taill√©
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1
            )
        
        generation_time = time.time() - start_time
        
        # D√©codage de la r√©ponse
        response = processor.decode(
            outputs[0], 
            skip_special_tokens=True
        )
        
        # Nettoyage de la r√©ponse
        if prompt in response:
            response = response.replace(prompt, "").strip()
        
        print(f"‚è±Ô∏è Temps d'analyse: {generation_time:.2f}s")
        print(f"üìã Diagnostic g√©n√©r√© ({len(response)} caract√®res)")
        
        return response
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse d'image: {e}")
        return None

def analyze_with_different_prompts(image_path: str, processor, model):
    """Analyse l'image avec diff√©rents prompts sp√©cialis√©s"""
    
    print("\n" + "="*60)
    print("üî¨ ANALYSE MULTI-PROMPTS")
    print("="*60)
    
    # Diff√©rents prompts pour diff√©rents aspects
    prompts = [
        {
            "title": "Diagnostic G√©n√©ral",
            "prompt": "Analyse cette image de plante. Identifie la maladie et d√©cris les sympt√¥mes visibles.",
            "max_tokens": 300
        },
        {
            "title": "Sympt√¥mes D√©taill√©s",
            "prompt": "D√©cris en d√©tail les sympt√¥mes visibles sur cette plante: couleur des feuilles, forme des taches, r√©partition des l√©sions.",
            "max_tokens": 250
        },
        {
            "title": "Traitements Recommand√©s",
            "prompt": "Bas√© sur l'image de cette plante malade, recommande des traitements efficaces et des mesures pr√©ventives.",
            "max_tokens": 300
        },
        {
            "title": "Diagnostic Expert",
            "prompt": "En tant qu'expert en phytopathologie, analyse cette image et fournis un diagnostic professionnel avec niveau de confiance.",
            "max_tokens": 350
        }
    ]
    
    results = []
    
    for i, prompt_info in enumerate(prompts, 1):
        print(f"\nüìã Analyse {i}: {prompt_info['title']}")
        print("-" * 40)
        
        response = analyze_plant_image(
            image_path=image_path,
            processor=processor,
            model=model,
            custom_prompt=prompt_info['prompt']
        )
        
        if response:
            print("üìù R√©ponse:")
            print(response)
            results.append({
                "title": prompt_info['title'],
                "response": response
            })
        else:
            print("‚ùå √âchec de l'analyse")
        
        print("-" * 40)
        
        # Pause entre les analyses
        if i < len(prompts):
            print("‚è≥ Pause de 3 secondes...")
            time.sleep(3)
    
    return results

def main():
    """Fonction principale"""
    
    print("üöÄ ANALYSE D'IMAGE DE PLANTE MALADE")
    print("=" * 50)
    
    # Chemin de l'image
    image_path = "/kaggle/input/tomato/tomato_early_blight.jpg"
    
    print(f"üìÅ Image √† analyser: {image_path}")
    
    # V√©rification de l'existence de l'image
    if not os.path.exists(image_path):
        print(f"‚ùå Image non trouv√©e: {image_path}")
        print("üí° V√©rifiez que le dataset tomato est bien attach√© √† votre notebook")
        return
    
    # Chargement du mod√®le multimodal
    processor, model = load_multimodal_model()
    
    if processor is None or model is None:
        print("‚ùå Impossible de charger le mod√®le multimodal")
        return
    
    # Menu de choix
    print("\nüéØ Choisissez le mode d'analyse:")
    print("1. Analyse simple avec prompt par d√©faut")
    print("2. Analyse multi-prompts (4 analyses diff√©rentes)")
    print("3. Analyse avec prompt personnalis√©")
    
    try:
        choice = input("\nVotre choix (1-3): ").strip()
        
        if choice == "1":
            # Analyse simple
            print("\nüîç Analyse simple...")
            response = analyze_plant_image(image_path, processor, model)
            
            if response:
                print("\nüìã DIAGNOSTIC COMPLET:")
                print("=" * 50)
                print(response)
                print("=" * 50)
        
        elif choice == "2":
            # Analyse multi-prompts
            results = analyze_with_different_prompts(image_path, processor, model)
            
            # R√©sum√© des r√©sultats
            print("\nüìä R√âSUM√â DES ANALYSES:")
            print("=" * 50)
            for result in results:
                print(f"\nüîç {result['title']}:")
                print(f"üìù {result['response'][:100]}...")
        
        elif choice == "3":
            # Analyse personnalis√©e
            custom_prompt = input("\nüå± Votre prompt personnalis√©: ").strip()
            
            if custom_prompt:
                response = analyze_plant_image(image_path, processor, model, custom_prompt)
                
                if response:
                    print("\nüìã R√âSULTAT:")
                    print("=" * 50)
                    print(response)
                    print("=" * 50)
            else:
                print("‚ùå Prompt vide")
        
        else:
            print("‚ùå Choix invalide")
            
    except KeyboardInterrupt:
        print("\nüëã Arr√™t demand√©")
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
    
    print("\nüéâ Analyse termin√©e!")

# Ex√©cution directe
if __name__ == "__main__":
    main() 