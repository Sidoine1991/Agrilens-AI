# =================================================================================
# Test de Diagnostic de Plantes - Gemma 3n E2B IT
# SpÃ©cialisÃ© pour l'application AgriLens AI
# =================================================================================

import os
import torch
import time
from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig
from PIL import Image
import requests
from io import BytesIO

# Configuration
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
MODEL_PATH = "/kaggle/input/gemma-3n/transformers/gemma-3n-e2b-it/1"

def load_model():
    """Charge le modÃ¨le pour le diagnostic"""
    try:
        print("ğŸŒ± Chargement du modÃ¨le pour diagnostic de plantes...")
        
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_block_size=16,
        )
        
        processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)
        model = AutoModelForImageTextToText.from_pretrained(
            MODEL_PATH,
            trust_remote_code=True,
            device_map="auto",
            quantization_config=bnb_config,
        )
        
        print("âœ… ModÃ¨le chargÃ© pour diagnostic!")
        return model, processor
        
    except Exception as e:
        print(f"âŒ Erreur de chargement: {e}")
        return None, None

def load_plant_image():
    """Charge une image de plante pour test"""
    try:
        # Image de tomate avec maladie (exemple)
        image_url = "https://images.unsplash.com/photo-1574323347407-f5e1ad6d020b?w=400"
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content))
        print(f"âœ… Image de plante chargÃ©e: {image.size}")
        return image
    except Exception as e:
        print(f"âŒ Erreur image: {e}")
        return None

def diagnose_plant(model, processor, image, prompt):
    """Effectue un diagnostic de plante"""
    try:
        print(f"\nğŸ” Diagnostic: {prompt}")
        print("-" * 40)
        
        # PrÃ©paration avec image
        inputs = processor(text=prompt, images=image, return_tensors="pt")
        
        # GÃ©nÃ©ration
        start_time = time.time()
        
        with torch.inference_mode():
            outputs = model.generate(
                **inputs,
                max_new_tokens=300,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
                pad_token_id=processor.tokenizer.eos_token_id
            )
        
        gen_time = time.time() - start_time
        
        # DÃ©codage
        response = processor.decode(outputs[0], skip_special_tokens=True)
        
        # Nettoyage
        if prompt in response:
            response = response.replace(prompt, "").strip()
        
        print(f"â±ï¸ Temps: {gen_time:.2f}s")
        print(f"ğŸ“‹ Diagnostic:")
        print(response)
        print("-" * 40)
        
        return response, gen_time
        
    except Exception as e:
        print(f"âŒ Erreur diagnostic: {e}")
        return None, 0

def test_plant_diagnosis():
    """Test complet du diagnostic de plantes"""
    
    print("ğŸŒ± Test de Diagnostic de Plantes - AgriLens AI")
    print("=" * 60)
    
    # 1. Chargement
    model, processor = load_model()
    if not model or not processor:
        print("âŒ Impossible de continuer")
        return
    
    # 2. Chargement image
    plant_image = load_plant_image()
    if not plant_image:
        print("âŒ Impossible de charger l'image")
        return
    
    # 3. Tests de diagnostic
    diagnostic_tests = [
        {
            "type": "Analyse gÃ©nÃ©rale",
            "prompt": "Analyse cette image de plante et identifie les problÃ¨mes visibles."
        },
        {
            "type": "SymptÃ´mes",
            "prompt": "DÃ©cris les symptÃ´mes visibles sur cette plante et leurs causes possibles."
        },
        {
            "type": "Traitement",
            "prompt": "BasÃ© sur cette image, quels traitements recommandes-tu pour cette plante?"
        },
        {
            "type": "PrÃ©vention",
            "prompt": "Comment peut-on prÃ©venir ces problÃ¨mes Ã  l'avenir?"
        }
    ]
    
    results = []
    
    for test in diagnostic_tests:
        print(f"\nğŸ”¬ {test['type']}")
        response, gen_time = diagnose_plant(model, processor, plant_image, test['prompt'])
        
        if response:
            results.append({
                'type': test['type'],
                'response': response,
                'time': gen_time,
                'success': True
            })
        else:
            results.append({
                'type': test['type'],
                'response': 'Ã‰chec',
                'time': 0,
                'success': False
            })
    
    # 4. RÃ©sumÃ©
    print("\n" + "=" * 60)
    print("ğŸ“Š RÃ‰SUMÃ‰ DES DIAGNOSTICS")
    print("=" * 60)
    
    successful = sum(1 for r in results if r['success'])
    total_time = sum(r['time'] for r in results if r['success'])
    
    print(f"âœ… Diagnostics rÃ©ussis: {successful}/{len(results)}")
    
    if successful > 0:
        avg_time = total_time / successful
        print(f"â±ï¸ Temps moyen: {avg_time:.2f}s")
        print(f"â±ï¸ Temps total: {total_time:.2f}s")
    
    print("\nğŸ‰ Test de diagnostic terminÃ©!")

if __name__ == "__main__":
    test_plant_diagnosis() 